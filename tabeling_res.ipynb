{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'output/HAR_outputdata/'\n",
    "paths = ['output/HAR_outputdata/', 'output/LSTM_outputdata/']\n",
    "\n",
    "result_list =[]\n",
    "\n",
    "train_pattern = r'Train Accuracy\\s+(\\{.*?\\})'\n",
    "test_pattern = r'Test Accuracy\\s+(\\{.*?\\})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        \n",
    "        file_path = os.path.join(path, f)\n",
    "        if os.path.isfile(file_path):  # Check if it's a file\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = file.read()\n",
    "    \n",
    "            \n",
    "        train_match = re.search(train_pattern, data, re.DOTALL)\n",
    "        if train_match:\n",
    "            train_accuracy_str = train_match.group(1)\n",
    "            train_accuracy = eval(train_accuracy_str) \n",
    "    \n",
    "        test_match = re.search(test_pattern, data, re.DOTALL)\n",
    "        if test_match:\n",
    "            test_accuracy_str = test_match.group(1)\n",
    "            test_accuracy = eval(test_accuracy_str) \n",
    "            \n",
    "        result_list.append({\n",
    "                'filename': f,\n",
    "                'train_accuracy': train_accuracy,\n",
    "                'test_accuracy': test_accuracy\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 9.322322111047433e-09,\n",
       " 'MAE': 3.21782075399625e-05,\n",
       " 'RSquared': 0.7243643620989295}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list[0]['train_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_list, columns=['filename', 'train_accuracy', 'test_accuracy'])\n",
    "df['train_RMSE'] = df['train_accuracy'].apply(lambda x: np.sqrt(x['MSE']) * 1e4)\n",
    "df['train_MAE'] = df['train_accuracy'].apply(lambda x: x['MAE'] * 1e5)\n",
    "df['train_R2'] = df['train_accuracy'].apply(lambda x : x['RSquared'])\n",
    "df['test_RMSE'] = df['test_accuracy'].apply(lambda x:np.sqrt(x['MSE']) * 1e4)\n",
    "df['test_MAE'] = df['test_accuracy'].apply(lambda x: x['MAE'] * 1e5)\n",
    "df['test_R2'] = df['test_accuracy'].apply(lambda x : x['RSquared'])\n",
    "\n",
    "df.drop(['train_accuracy', 'test_accuracy'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['filename'].str.contains('.ipynb_checkpoints')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Table Caption}\n",
      "\\label{tab:table_label}\n",
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "              filename &  train\\_RMSE &  train\\_MAE &  train\\_R2 &  test\\_RMSE &  test\\_MAE &  test\\_R2 \\\\\n",
      "\\midrule\n",
      "    .ipynb\\_checkpoints &    0.837896 &   3.082954 &  0.746597 &   0.322405 &  1.729993 & 0.498232 \\\\\n",
      "    .ipynb\\_checkpoints &    0.983667 &   3.474004 &  0.578417 &   0.265284 &  1.624685 & 0.503734 \\\\\n",
      "        1\\_20\\_False.txt &    0.977140 &   3.235962 &  0.717691 &   0.331155 &  1.650938 & 0.591224 \\\\\n",
      "         1\\_20\\_True.txt &    1.145618 &   3.401024 &  0.611947 &   0.329386 &  1.749738 & 0.595580 \\\\\n",
      "        1\\_30\\_False.txt &    1.298342 &   5.150203 &  0.501587 &   0.419559 &  2.055844 & 0.343843 \\\\\n",
      "         1\\_30\\_True.txt &    1.116348 &   3.794401 &  0.631523 &   0.331928 &  1.922814 & 0.589313 \\\\\n",
      "       20\\_20\\_False.txt &    0.935274 &   3.353931 &  0.618878 &   0.276741 &  1.747621 & 0.459942 \\\\\n",
      "        20\\_20\\_True.txt &    0.928321 &   3.269361 &  0.624524 &   0.270509 &  1.875219 & 0.483994 \\\\\n",
      "        5\\_20\\_False.txt &    1.155167 &   3.654936 &  0.518361 &   0.335160 &  1.850512 & 0.457743 \\\\\n",
      "         5\\_20\\_True.txt &    0.850499 &   2.902638 &  0.738916 &   0.286023 &  1.656677 & 0.605087 \\\\\n",
      "        5\\_30\\_False.txt &    0.819043 &   3.041310 &  0.757872 &   0.292386 &  1.936549 & 0.587319 \\\\\n",
      "         5\\_30\\_True.txt &    0.837896 &   3.082954 &  0.746597 &   0.322405 &  1.729993 & 0.498232 \\\\\n",
      " HAR\\_1\\_False\\_False.txt &    0.965522 &   3.217821 &  0.724364 &   0.313588 &  1.744372 & 0.633443 \\\\\n",
      "  HAR\\_1\\_False\\_True.txt &    1.013387 &   3.166767 &  0.696358 &   0.321710 &  1.614133 & 0.614211 \\\\\n",
      "  HAR\\_1\\_True\\_False.txt &    0.959656 &   3.141167 &  0.727703 &   0.308457 &  1.709955 & 0.645342 \\\\\n",
      "   HAR\\_1\\_True\\_True.txt &    1.017561 &   3.147095 &  0.693852 &   0.318730 &  1.598987 & 0.621324 \\\\\n",
      "HAR\\_20\\_False\\_False.txt &    0.903008 &   3.670307 &  0.644721 &   0.298359 &  2.362422 & 0.372274 \\\\\n",
      " HAR\\_20\\_False\\_True.txt &    0.984049 &   3.476323 &  0.578090 &   0.264966 &  1.622384 & 0.504921 \\\\\n",
      " HAR\\_20\\_True\\_False.txt &    0.897455 &   3.655432 &  0.649077 &   0.296358 &  2.336517 & 0.380663 \\\\\n",
      "  HAR\\_20\\_True\\_True.txt &    0.983667 &   3.474004 &  0.578417 &   0.265284 &  1.624685 & 0.503734 \\\\\n",
      " HAR\\_5\\_False\\_False.txt &    0.859990 &   3.084718 &  0.733057 &   0.283158 &  1.829297 & 0.612958 \\\\\n",
      "  HAR\\_5\\_False\\_True.txt &    0.921598 &   3.068768 &  0.693441 &   0.281429 &  1.576588 & 0.617670 \\\\\n",
      "  HAR\\_5\\_True\\_False.txt &    0.853781 &   3.044834 &  0.736898 &   0.278423 &  1.794599 & 0.625795 \\\\\n",
      "   HAR\\_5\\_True\\_True.txt &    0.920131 &   3.062030 &  0.694416 &   0.280259 &  1.578079 & 0.620841 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12761/4221154463.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=False, caption='Table Caption', label='tab:table_label')\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX table\n",
    "latex_table = df.to_latex(index=False, caption='Table Caption', label='tab:table_label')\n",
    "\n",
    "# Print LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
