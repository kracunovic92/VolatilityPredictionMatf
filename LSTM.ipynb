{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 19:10:18.843331: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparationLSTM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        future = 1,\n",
    "        lag = 20,\n",
    "        semi_variance: bool = False,\n",
    "        jump_detect: bool = True,\n",
    "        log_transform: bool = True,\n",
    "        min_max_scaler: bool = True,\n",
    "        period_train=list(\n",
    "            [\n",
    "                pd.to_datetime(\"20030910\", format=\"%Y%m%d\"),\n",
    "                pd.to_datetime(\"20091231\", format=\"%Y%m%d\"),\n",
    "            ]\n",
    "        ),\n",
    "        period_test=list(\n",
    "            [\n",
    "                pd.to_datetime(\"20100101\", format=\"%Y%m%d\"),\n",
    "                pd.to_datetime(\"20101231\", format=\"%Y%m%d\"),\n",
    "            ]\n",
    "        ),\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.future = future\n",
    "        self.lag = lag\n",
    "        self.semi_variance = semi_variance\n",
    "        self.jump_detect = jump_detect\n",
    "        self.log_transform = log_transform\n",
    "        self.min_max_scaler = min_max_scaler\n",
    "        self.period_train = period_train\n",
    "        self.period_test = period_test\n",
    "\n",
    "        # Predefined generated output\n",
    "        self.training_set = None  # data frames\n",
    "        self.testing_set = None  # data frames\n",
    "        self.train_matrix = None\n",
    "        self.train_y = None\n",
    "        self.test_matrix = None\n",
    "        self.test_y = None\n",
    "        self.future_values = None\n",
    "        self.historical_values = None\n",
    "        self.df_processed_data = None\n",
    "        self.applied_scaler_features = None\n",
    "        self.applied_scaler_targets = None\n",
    "\n",
    "    def jump_detection(self):\n",
    "        \n",
    "        tmp = self.data.copy()\n",
    "        threshold = tmp['RV'].rolling(window = 200).std() * 4\n",
    "        threshold.fillna(1,inplace=True)\n",
    "        on_start_rows = tmp.shape[0]\n",
    "        tmp['larger'] =tmp['RV'] > threshold\n",
    "\n",
    "        tmp = tmp[tmp['larger'] == False]\n",
    "        tmp.drop(['larger'], axis=1, inplace=True)\n",
    "\n",
    "        on_end_rows = tmp.shape[0]\n",
    "        self.data_filltered_on_jump = (on_start_rows- on_end_rows) / on_start_rows * 100\n",
    "        self.data = tmp.copy()\n",
    "\n",
    "    def data_scaling(self):\n",
    "\n",
    "        if self.log_transform:\n",
    "            self.df.RV = np.log(self.df.RV)\n",
    "            if self.semi_variance:\n",
    "                self.df['RV+'] = np.log(self.df['RV+'])\n",
    "                self.df['RV-'] = np.log(self.df['RV-'])\n",
    "\n",
    "        if self.min_max_scaler:\n",
    "            s = MinMaxScaler()\n",
    "            self.applied_scaler_features = s\n",
    "            self.df['RV'] = s.fit_transform(self.df['RV'].values.reshape(-1, 1))\n",
    "            if self.semi_variance:\n",
    "                self.df['RV+'] = s.fit_transform(\n",
    "                    self.df['RV+'].values.reshape(-1, 1)\n",
    "                )\n",
    "                self.df['RV-'] = s.fit_transform(\n",
    "                    self.df['RV-'].values.reshape(-1, 1)\n",
    "                )\n",
    "\n",
    "    def future_averages(self):\n",
    "\n",
    "        data = self.df[[\"DATE\", \"RV\"]].copy()\n",
    "\n",
    "        for i in range(self.future):\n",
    "            data[\"Target{}\".format(i + 1)] = data['RV'].shift(-(i + 1))\n",
    "        data = data.dropna()\n",
    "\n",
    "        help_df = data.drop([\"DATE\", \"RV\"], axis=1)\n",
    "\n",
    "        df_output = data[[\"DATE\", \"RV\"]]\n",
    "        df_output[\"Target\"] = help_df.mean(axis=1)\n",
    "\n",
    "        df_output = df_output.drop([\"RV\"], axis=1)\n",
    "\n",
    "        self.future_values = df_output\n",
    "\n",
    "    def historical_lag_transformation(self):\n",
    "\n",
    "        df = self.df[[\"DATE\", \"RV\"]].copy()\n",
    "        for i in range((self.lag - 1)):\n",
    "            df[\"lag_{}\".format(i + 1)] = df['RV'].shift(+(i + 1))\n",
    "\n",
    "        self.historical_values = df\n",
    "\n",
    "    \n",
    "    def generate_dataset(self):\n",
    "\n",
    "        self.jump_detection()  # outliers\n",
    "\n",
    "        self.future_averages() # targets\n",
    "\n",
    "        if self.log_transform:\n",
    "            self.future_values.future = np.log(self.future_values.future)\n",
    "            s_targets = MinMaxScaler()\n",
    "            self.applied_scaler_targets = s_targets\n",
    "            self.future_values.future = s_targets.fit_transform(\n",
    "                self.future_values.future.values.reshape(-1, 1)\n",
    "            )\n",
    "\n",
    "        self.data_scaling()  # data scaling after future value generation\n",
    "        self.historical_lag_transformation()\n",
    "\n",
    "        # merging the two data sets\n",
    "        data_set_complete = self.future_values.merge(\n",
    "            self.historical_values, how=\"right\", on=\"DATE\"\n",
    "        )\n",
    "        data_set_complete = data_set_complete.dropna()\n",
    "        data_set_complete.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        if self.semi_variance:\n",
    "            df_tmp = self.df[[\"DATE\", \"RV-\"]]\n",
    "            data_set_complete = data_set_complete.merge(df_tmp, on=\"DATE\")\n",
    "\n",
    "        self.df_processed_data = data_set_complete\n",
    "\n",
    "    def generate_training_test_split(self):\n",
    "\n",
    "        self.generate_dataset()\n",
    "\n",
    "        data = self.df_processed_data.copy()\n",
    "        data.index = pd.to_datetime(data.index, format = \"%Y-%m-%d\")\n",
    "\n",
    "        data_train = data.loc[(data.index >= self.period_train[0]) &(data.index <= self.period_train[1])].reset_index(drop= True)\n",
    "        data_test = data.loc[(data.index >= self.period_test[0]) &(data.index <= self.period_test[1])].reset_index(drop = True)\n",
    "\n",
    "        self.training_set = data_train\n",
    "        self.testing_set = data_test\n",
    "\n",
    "\n",
    "    def generate_validation_split(self):\n",
    "\n",
    "        self.train_matrix = self.training_set.drop(columns={\"DATE\", \"Tuture\"}).values\n",
    "        self.train_y = self.training_set[[\"Target\"]].values\n",
    "\n",
    "        self.test_matrix = self.testing_set.drop(columns={\"DATE\", \"Tuture\"}).values\n",
    "        self.test_y = self.testing_set[[\"Tuture\"]].values\n",
    "\n",
    "        n_features = 1\n",
    "\n",
    "        train_shape_rows = self.train_matrix.shape[0]\n",
    "        train_shape_columns = self.train_matrix.shape[1]\n",
    "\n",
    "        self.train_matrix = self.train_matrix.reshape(\n",
    "            (train_shape_rows, train_shape_columns, n_features)\n",
    "        )\n",
    "\n",
    "        test_shape_rows = self.test_matrix.shape[0]\n",
    "        test_shape_columns = self.train_matrix.shape[1]\n",
    "\n",
    "        self.test_matrix = self.test_matrix.reshape(\n",
    "            (test_shape_rows, test_shape_columns, n_features)\n",
    "        )\n",
    "\n",
    "\n",
    "    def prepare_all(self):\n",
    "\n",
    "        if self.training_set is None:\n",
    "            self.generate_training_test_split()\n",
    "\n",
    "        if self.train_matrix is None:\n",
    "            self.generate_validation_split()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        training_set,\n",
    "        testing_set,\n",
    "        train_matrix,\n",
    "        train_y,\n",
    "        test_matrix,\n",
    "        test_y,\n",
    "        activation=tf.nn.elu,\n",
    "        epochs=50,\n",
    "        learning_rate=0.01,\n",
    "        layer_one=40,\n",
    "        layer_two=40,\n",
    "        layer_three=0,\n",
    "        layer_four=0,\n",
    "    ):\n",
    "        self.training_set = training_set\n",
    "        self.testing_set = testing_set\n",
    "        self.train_matrix = train_matrix\n",
    "        self.train_y = train_y\n",
    "        self.test_matrix = test_matrix\n",
    "        self.test_y = test_y\n",
    "        self.activation = activation\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layer_one = int(layer_one)\n",
    "        self.layer_two = int(layer_two)\n",
    "        self.layer_three = int(layer_three)\n",
    "        self.layer_four = int(layer_four)\n",
    "\n",
    "        # Predefined output\n",
    "        self.fitted_model = None\n",
    "        self.prediction_train = None\n",
    "        self.prediction_test = None\n",
    "        self.test_accuracy = None\n",
    "        self.train_accuracy = None\n",
    "        self.fitness = None\n",
    "\n",
    "    def train_lstm(self):\n",
    "\n",
    "        m = tf.keras.models.Sequential()\n",
    "        m.add(\n",
    "            tf.keras.layers.LSTM(\n",
    "                self.layer_one,\n",
    "                activation=self.activation,\n",
    "                return_sequences=True,\n",
    "                input_shape=(int(self.train_matrix.shape[int(1)]), int(1)),\n",
    "            )\n",
    "        )\n",
    "        if self.layer_two > 0:\n",
    "            if self.layer_three > 0:\n",
    "                if self.layer_four > 0:\n",
    "                    m.add(\n",
    "                        tf.keras.layers.LSTM(\n",
    "                            self.layer_two,\n",
    "                            activation=self.activation,\n",
    "                            return_sequences=True,\n",
    "                        )\n",
    "                    )\n",
    "                    m.add(\n",
    "                        tf.keras.layers.LSTM(\n",
    "                            self.layer_three,\n",
    "                            activation=self.activation,\n",
    "                            return_sequences=True,\n",
    "                        )\n",
    "                    )\n",
    "                    m.add(\n",
    "                        tf.keras.layers.LSTM(\n",
    "                            self.layer_four, activation=self.activation,\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    m.add(\n",
    "                        tf.keras.layers.LSTM(\n",
    "                            self.layer_two,\n",
    "                            activation=self.activation,\n",
    "                            return_sequences=True,\n",
    "                        )\n",
    "                    )\n",
    "                    m.add(\n",
    "                        tf.keras.layers.LSTM(\n",
    "                            self.layer_three, activation=self.activation,\n",
    "                        )\n",
    "                    )\n",
    "            else:\n",
    "                m.add(tf.keras.layers.LSTM(self.layer_two, activation=self.activation))\n",
    "        m.add(tf.keras.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "        o = tf.keras.optimizers.Adam(\n",
    "                lr=self.learning_rate,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=None,\n",
    "                decay=0.0,\n",
    "                amsgrad=False,\n",
    "            )\n",
    "        \n",
    "        m.compile(optimizer=o, loss=tf.keras.losses.logcosh)\n",
    "\n",
    "        es = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", mode=\"min\", patience=10, verbose=1,\n",
    "        )\n",
    "\n",
    "        m.fit(\n",
    "            self.train_matrix,\n",
    "            self.train_y,\n",
    "            epochs=self.epochs,\n",
    "            verbose=1,\n",
    "            callbacks=[es],  # added\n",
    "            validation_data=(self.test_matrix, self.test_y,),\n",
    "        )\n",
    "\n",
    "        self.fitted_model = m\n",
    "\n",
    "\n",
    "    def predict_lstm(self):\n",
    "\n",
    "        if self.fitted_model is None:\n",
    "            self.train_lstm()\n",
    "\n",
    "        self.prediction_train = self.fitted_model.predict(self.train_matrix)\n",
    "        self.prediction_test = self.fitted_model.predict(self.test_matrix)\n",
    "\n",
    "    \n",
    "    def make_accuracy_measures(self):\n",
    "        if self.prediction_test is None:\n",
    "            self.predict_lstm()\n",
    "\n",
    "        test_accuracy = {\n",
    "            \"MSE\": metrics.mean_squared_error(\n",
    "                self.testing_set[\"future\"], self.prediction_test\n",
    "            ),\n",
    "            \"MAE\": metrics.mean_absolute_error(\n",
    "                self.testing_set[\"future\"], self.prediction_test\n",
    "            ),\n",
    "            \"RSquared\": metrics.r2_score(\n",
    "                self.testing_set[\"future\"], self.prediction_test\n",
    "            ),\n",
    "        }\n",
    "        train_accuracy = {\n",
    "            \"MSE\": metrics.mean_squared_error(\n",
    "                self.training_set[\"future\"], self.prediction_train\n",
    "            ),\n",
    "            \"MAE\": metrics.mean_absolute_error(\n",
    "                self.training_set[\"future\"], self.prediction_train\n",
    "            ),\n",
    "            \"RSquared\": metrics.r2_score(\n",
    "                self.training_set[\"future\"], self.prediction_train\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        self.test_accuracy = test_accuracy\n",
    "        self.train_accuracy = train_accuracy\n",
    "        self.fitness = self.train_accuracy[\"RSquared\"] + self.test_accuracy[\"RSquared\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
